{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e6dfac76-f528-4dd4-bd69-9d88727cc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import ast\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe171cc",
   "metadata": {},
   "source": [
    "# 1. Paragraph에서 숫자 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8d9ad151-0331-489f-8fc6-d3c7b15c9b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_path = glob.glob('paragraph/income_quantile*/PL_*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9e6ee570-7b77-47e0-927e-4dff90d90284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. paragraph에서 숫자 추출\n",
    "col = 'desc'\n",
    "\n",
    "def extract_numbers_after_country(text):\n",
    "    # 국가 코드 중 하나 찾기\n",
    "    match = re.search(r\"(POL|SVK|CZE|HUN)\", text)\n",
    "    if not match:\n",
    "        return []\n",
    "\n",
    "    # 그 위치 이후의 문자열 자르기\n",
    "    start_idx = match.end()\n",
    "    tail = text[start_idx:]\n",
    "\n",
    "    # 숫자 추출 (정수, 소수, 음수 포함)\n",
    "    numbers = re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", tail)\n",
    "    return [float(num) for num in numbers]\n",
    "\n",
    "for path in all_path:\n",
    "    df = pd.read_csv(path)\n",
    "    df[\"numbers\"] = df[col].astype(str).apply(extract_numbers_after_country)\n",
    "    df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4cf9cc",
   "metadata": {},
   "source": [
    "# 2-1. feature normalization (새로운 feature인 경우)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "cd275203-7a30-40c3-8f0c-1b4f275e2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-1. feature normalization (새로운 feature가 주어졌을 경우)\n",
    "\n",
    "score = {\n",
    "    'Very Low': 0,\n",
    "    'Low': 1,\n",
    "    'Medium': 2,\n",
    "    'High': 3,\n",
    "    'Very High': 4,\n",
    "}\n",
    "\n",
    "isshot = False\n",
    "\n",
    "all_result = glob.glob('class/income_quantile*/*/*.csv')\n",
    "\n",
    "\n",
    "for path in all_result:\n",
    "    parameter = path.split('/')[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    if isshot:\n",
    "        paragraph = pd.read_csv(f'./paragraph/{parameter}/PL_SK_CZ_HU_{parameter}_adm2_9549_o1mini_landuse_wo_neighbor_paragraph_output.csv')\n",
    "    else:\n",
    "        paragraph = pd.read_csv(f'./paragraph/{parameter}/PL_{parameter}_adm2_9549_paragraph_output.csv')\n",
    "    \n",
    "    # 문자열 -> 리스트 변환\n",
    "    paragraph['numbers'] = paragraph['numbers'].apply(ast.literal_eval)\n",
    "    vector_df = paragraph['numbers'].apply(pd.Series)\n",
    "    # 모든 값이 같은 컬럼만 골라냄\n",
    "    constant_columns = vector_df.columns[vector_df.nunique() == 1]\n",
    "    \n",
    "    # 제거\n",
    "    vector_df = vector_df.drop(columns=constant_columns)\n",
    "\n",
    "    vector_df.columns = [f\"feature_{i}\" for i in range(vector_df.shape[1])]\n",
    "\n",
    "    # feature 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_array = scaler.fit_transform(vector_df)\n",
    "    normalized_df = pd.DataFrame(scaled_array, columns=vector_df.columns)\n",
    "\n",
    "    df_expanded = pd.concat([paragraph[[\"area_id\", 'desc']], normalized_df], axis=1)\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    try:\n",
    "        df['cluster'] = df['score'].apply(lambda s: score[s])\n",
    "    except:\n",
    "        print(path)\n",
    "        continue\n",
    "    df = pd.merge(df, df_expanded, how='inner', on='area_id')\n",
    "        \n",
    "    df = df.drop(columns=['score', 'ground_truth', 'desc'])\n",
    "    filename = path.split('/')[-1].split('.')[0]\n",
    "    df.to_csv(f'./data/income_quantile/{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c76ac",
   "metadata": {},
   "source": [
    "# 2-2. 이미 feature extraction 진행한 경우, 원래 값 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b89d6470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income_quantile4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'PL_income_quantile1_adm2_9549_paragraph_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126227/3307446542.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mindicator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mPL_income_quantile1_adm2_9549_paragraph_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'area_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PL_income_quantile1_adm2_9549_paragraph_output' is not defined"
     ]
    }
   ],
   "source": [
    "score = {\n",
    "    'Very Low': 0,\n",
    "    'Low': 1,\n",
    "    'Medium': 2,\n",
    "    'High': 3,\n",
    "    'Very High': 4,\n",
    "}\n",
    "\n",
    "new_class = glob.glob(f'./class/income_quantile*/*/*.csv')\n",
    "\n",
    "name = 'income_quantile'\n",
    "model = 'o4-mini'\n",
    "\n",
    "os.makedirs(f'./data/{name}', exist_ok=True)\n",
    "for csv in new_class:\n",
    "    df = pd.read_csv(csv)\n",
    "    try: \n",
    "        df['cluster_new'] = df['score'].apply(lambda x: score[x])\n",
    "    except:\n",
    "        print(csv)\n",
    "        continue\n",
    "    filename = csv.split('/')[-1]\n",
    "    o1filename = filename.replace(model, 'o1-mini').replace('_addr', '').replace('_random', '')\n",
    "    feature = pd.read_csv(f'./data/o1mini/{o1filename}')\n",
    "    df = df.merge(feature, on='area_id', how='inner')\n",
    "    df['cluster'] = df['cluster_new']\n",
    "    df = df.drop(columns=['ground_truth', 'score', 'cluster_new'])\n",
    "    if not os.path.exists(f'./data/{name}/{filename}'):\n",
    "        df.to_csv(f'./data/{name}/{filename}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "aff4c418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  area_id      score  sample_val  ground_val  cluster_new\n",
      "0   HU313   Very Low       424.0         424            0\n",
      "1   PL812        Low       737.6         603            1\n",
      "2   PL714        Low       737.6         648            1\n",
      "3   PL218        Low       737.6         678            1\n",
      "4   PL912        Low       737.6         690            1\n",
      "5   PL411        Low       737.6        1069            1\n",
      "6   PL414     Medium      1328.5        1327            2\n",
      "7   PL517     Medium      1328.5        1330            2\n",
      "8   CZ064       High      4336.0        4336            3\n",
      "9   CZ010  Very High      6979.0        6979            4\n",
      "Empty DataFrame\n",
      "Columns: [area_id, score, sample_val, ground_val, cluster_new, cluster, feature_0, feature_1, feature_2, feature_3, feature_4, feature_5, feature_6]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['ground_truth'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126227/1983617584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cluster_new'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ground_truth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster_new'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./data/shot/{filename}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./data/shot/{filename}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UNet/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UNet/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4911\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4912\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4913\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4914\u001b[0m         )\n\u001b[1;32m   4915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UNet/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4148\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4150\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UNet/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4183\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4185\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4186\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/UNet/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['ground_truth'] not found in axis\""
     ]
    }
   ],
   "source": [
    "score = {\n",
    "    'Very Low': 0,\n",
    "    'Low': 1,\n",
    "    'Medium': 2,\n",
    "    'High': 3,\n",
    "    'Very High': 4,\n",
    "}\n",
    "\n",
    "# os.makedirs(f'./data/{name}')\n",
    "for csv in new_class:\n",
    "    df = pd.read_csv(csv)\n",
    "    try: \n",
    "        df['cluster_new'] = df['score'].apply(lambda x: score[x])\n",
    "    except:\n",
    "        print(csv)\n",
    "        continue\n",
    "    filename = csv.split('/')[-1]\n",
    "    feature = pd.read_csv(f'./data/o1mini/{filename}')\n",
    "    print(df)\n",
    "    df = df.merge(feature, on='area_id', how='inner')\n",
    "    df['cluster'] = df['cluster_new']\n",
    "    print(df)\n",
    "    df = df.drop(columns=['ground_truth', 'score', 'cluster_new'])\n",
    "    if not os.path.exists(f'./data/shot/{filename}'):\n",
    "        df.to_csv(f'./data/shot/{filename}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e77c1e",
   "metadata": {},
   "source": [
    "# 3. 결과 중 총 class 개수가 5 미만인 것 확인(다른 POG 사용해야 함.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ef6e5c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/income_quantile/PL_income_quantile4_classification_o4-mini_10shots_iter_num_1_class_sample_6.csv [1, 2, 3, 4]\n",
      "./data/income_quantile/PL_income_quantile1_classification_o4-mini_10shots_iter_num_2_class_sample_8.csv [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# 3. 결과 중 총 class 개수가 5 미만인 것 확인(다른 POG 사용해야 함.)\n",
    "\n",
    "all_result = glob.glob(f'./data/income_quantile/*.csv')\n",
    "\n",
    "for path in all_result:\n",
    "    df = pd.read_csv(path)\n",
    "    if len(df['cluster'].unique()) != 5:\n",
    "                \n",
    "        # 고유값 정렬해서 매핑 딕셔너리 만들기\n",
    "        unique_sorted = sorted(df['cluster'].unique())\n",
    "        mapping = {old: new for new, old in enumerate(unique_sorted)}\n",
    "\n",
    "        # 매핑 적용\n",
    "        df['cluster'] = df['cluster'].map(mapping)\n",
    "        df.to_csv(path, index=False)\n",
    "        print(path, unique_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d70f5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
